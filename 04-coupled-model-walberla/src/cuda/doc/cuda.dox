
namespace walberla{
/*!

\page cudaPage Overview of waLBerla CUDA support

\brief waLBerla CUDA concepts


\section cudaField Fields on GPU


\subsection cudaFieldOverview Creating GPU fields and copy them between host and device

   \code
   // create a CPU field and a GPU field of same size and with same layout
   GhostLayerField<double,4> h_f ( 16,20,30,    1, 42.0, field::fzyx );
   cuda::GPUField<double>    d_f ( 16,20,30, 4, 1,  field::fzyx );

   cuda::fieldCpy( d_f, h_f ); // copy from host to device
   some_kernel_wrapper( d_f ); // run some kernel
   cuda::fieldCpy( h_f, d_f ); // copy field data back to host
   \endcode

   Similarities and Differences of CPU and GPU field
   - cuda::GPUField corresponds to field::GhostLayerField
   - fSize is a template parameter for CPU fields and a normal parameter for GPUFields
   - CPU field iterators correspond to FieldAccessors (see next section)

\subsection cudaFieldAccess Writing CUDA kernels operating on GPUFields

  \image html cuda/doc/fieldAccess.png "Accessing fields in CUDA kernels"

   When writing a kernel that operates on a field, the first task is to distribute the data to CUDA threads and blocks.
   We need a function $(blockIdx, threadIdx) \\rightarrow (x,y,z)$ or $(blockIdx, threadIdx) \\rightarrow (x,y,z,f)$.
   The optimal mapping depends on many parameters: for example which layout the field has, the extends of each coordinate,
   hardware parameters like warp-size, etc.
   Thus this indexing function is abstracted. A few indexing strategies are already implemented which can be
   substituted by custom strategies.
   A indexing strategy consists of two classes: and somewhat complex Indexing class, which manages the
   indexing on the host-side and a lightweight Accessor class, which is passed to the CUDA kernel.

   An indexing scheme is very similar to the iterator concept, it defines the bounds of the iteration, which is not necessarily the
   complete field but could also be a certain sub-block, for example the ghost layer in a certain direction.


   Lets start to write a simple kernel that doubles all values stored in a field:
   \code
   #include "cuda/FieldAccessor.h"

   __global__ void kernel_double( cuda::FieldAccessor<double> f )
   {
      f.set( blockIdx, threadIdx );
      f.get() *= 2.0;
   }
   \endcode
   We do not have to care about indexing, the cuda::FieldAccessor takes care of that. So this is a generic kernel that operates
   on double fields. Using the cuda::FieldAccessor the current and neighboring values can be accessed and manipulated.

   This kernel can be called like this:
   \code
   cuda::FieldIndexing<double> indexing = cuda::FieldIndexing<double>::sliceBeforeGhostLayerXYZ( field, 1, stencil::E, true );
   kernel_double<<< iter.gridDim(), iter.blockDim() >>> ( iter.gpuAccess() );
   \endcode
   In the example above we only iterate over a slice of the field. Of course we can also iterate over the complete field, there are
   various static member functions in a Indexing class to create certain iteration patterns.
   The Indexing class encapsulates the information of how to launch the kernel (blockDim and gridDim) and holds the Accessor class that
   is passed to the kernel.

   Two indexing strategies are currently provided:
      - cuda::FieldIndexing   and  cuda::FieldAccessor (general, but slow )
      - cuda::FieldIndexingXYZ  and cuda::FieldAccessorXYZ ( optimized for cell based iterating over bigger chunks, for fields where xSize bigger than warpSize )

 \section cudaKernelWrapper Calling CUDA kernels from CPP files
      \copydoc cuda::Kernel



*/
}
